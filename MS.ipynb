{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Combinaison des données...\n",
      "\n",
      "Traitement des données MesParcelles...\n",
      "Standardisation des données MesParcelles...\n",
      "Après filtrage : 8 lignes\n",
      "Agrégation des données par exploitation (siret_exploitation)...\n",
      "Données agrégées par exploitation : 1 exploitations\n",
      "\n",
      "Traitement des données SMAG...\n",
      "Standardisation des données SMAG...\n",
      "Agrégation des données par exploitation (siret_exploitation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MonirNajem\\AppData\\Local\\Temp\\ipykernel_28896\\564241515.py:228: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  aggregated = df.groupby(siret_column).apply(weighted_average).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données agrégées par exploitation : 201 exploitations\n",
      "\n",
      "Colonnes dans les données standardisées:\n",
      "MesParcelles: ['siret_exploitation', 'engrais_utilises', 'Solution Liquide N 39_dose_kg_ha', 'engrais_non_icv', 'non_icv_N_kg_ha', 'non_icv_P_kg_ha', 'non_icv_K_kg_ha', 'source']\n",
      "SMAG: ['siret_exploitation', 'engrais_utilises', 'engrais_non_icv', 'non_icv_N_kg_ha', 'non_icv_P_kg_ha', 'non_icv_K_kg_ha', 'source']\n",
      "\n",
      "Résumé des données combinées:\n",
      "Nombre total d'observations: 202\n",
      "Nombre d'exploitations uniques: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MonirNajem\\AppData\\Local\\Temp\\ipykernel_28896\\564241515.py:228: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  aggregated = df.groupby(siret_column).apply(weighted_average).reset_index()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'culture'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MonirNajem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'culture'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 284\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Standardisation et combinaison\u001b[39;00m\n\u001b[0;32m    283\u001b[0m standardizer \u001b[38;5;241m=\u001b[39m FertilizerStandardizer()\n\u001b[1;32m--> 284\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m \u001b[43mstandardizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_sources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmag_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# Export des résultats\u001b[39;00m\n\u001b[0;32m    287\u001b[0m combined_data\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresultats_standardisation_par_exploitation.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[15], line 263\u001b[0m, in \u001b[0;36mFertilizerStandardizer.combine_sources\u001b[1;34m(self, mesparcelles_data, smag_data)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre total d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combined)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexploitations uniques: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msiret_exploitation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre de cultures uniques: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcombined\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mculture\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mListe des cultures uniques:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mculture\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32mc:\\Users\\MonirNajem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\MonirNajem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'culture'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class FertilizerStandardizer:\n",
    "    def __init__(self):\n",
    "        # Garder les mêmes initialisations...\n",
    "        self.icv_fertilizer_list = [\"Solution Liquide N 39\"]\n",
    "        self.default_mineral_density = 1.325\n",
    "        self.organic_solid_density = 1000\n",
    "        self.organic_liquid_density = 1.0\n",
    "        self.type_mapping = {\n",
    "            \"Fertilisation et amendement organique\": \"engrais organiques\",\n",
    "            \"Fertilisation et amendement mineral - foliaire inclus\": \"engrais mineraux\",\n",
    "            \"Fertilisation organique\": \"engrais organiques\",\n",
    "            \"Fertilisation minérale\": \"engrais mineraux\"\n",
    "        }\n",
    "\n",
    "    # Garder les méthodes auxiliaires identiques...\n",
    "    def standardize_fertilizer_name(self, name):\n",
    "        if pd.isna(name):\n",
    "            return name\n",
    "        name = str(name).upper()\n",
    "        name = re.sub(r'[^\\w\\s]', ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name)\n",
    "        return name.strip()\n",
    "\n",
    "    def is_in_icv_list(self, fertilizer_name):\n",
    "        std_name = self.standardize_fertilizer_name(fertilizer_name)\n",
    "        std_icv_list = [self.standardize_fertilizer_name(name) for name in self.icv_fertilizer_list]\n",
    "        return std_name in std_icv_list\n",
    "\n",
    "    def standardize_type_engrais(self, intervention_type):\n",
    "        if pd.isna(intervention_type):\n",
    "            return \"engrais mineraux\"\n",
    "        type_std = self.type_mapping.get(intervention_type)\n",
    "        return type_std if type_std else \"engrais mineraux\"\n",
    "\n",
    "    def calculate_nutrients(self, row):\n",
    "        \"\"\"Calcule les teneurs en nutriments NPK pour les engrais non-ICV\"\"\"\n",
    "        try:\n",
    "            if not row['in_icv_list']:\n",
    "                if row['type_engrais'] == 'engrais organiques':\n",
    "                    # Pour les engrais organiques, les compositions sont en kg/m³\n",
    "                    # On utilise l'hypothèse 1T = 1m³\n",
    "                    volume_m3 = row['quantite_totale'] if row['unite_intrant_intervention'].upper() == 'M3' \\\n",
    "                        else row['quantite_kg'] / self.organic_solid_density\n",
    "                    \n",
    "                    row['N_kg_ha'] = row['fertilisant.composition.n_total'] * volume_m3 / row['surface_travaillee_ha']\n",
    "                    row['P_kg_ha'] = row['fertilisant.composition.p'] * volume_m3 / row['surface_travaillee_ha']\n",
    "                    row['K_kg_ha'] = row['fertilisant.composition.k'] * volume_m3 / row['surface_travaillee_ha']\n",
    "                else:\n",
    "                    # Pour les engrais minéraux, les compositions sont en pourcentage\n",
    "                    row['N_kg_ha'] = row['dose_kg_ha'] * row['fertilisant.composition.n_total'] / 100\n",
    "                    row['P_kg_ha'] = row['dose_kg_ha'] * row['fertilisant.composition.p'] / 100\n",
    "                    row['K_kg_ha'] = row['dose_kg_ha'] * row['fertilisant.composition.k'] / 100\n",
    "            return row\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du calcul des nutriments pour l'engrais {row['libelle']}: {str(e)}\")\n",
    "            return row\n",
    "\n",
    "    def convert_to_kg(self, row):\n",
    "        # Garder la même logique de conversion...\n",
    "        try:\n",
    "            if pd.isna(row.get('unite_intrant_intervention')) or pd.isna(row.get('quantite_totale')):\n",
    "                return np.nan\n",
    "                \n",
    "            unite = str(row.get('unite_intrant_intervention', '')).upper()\n",
    "            type_engrais = str(row.get('type_engrais', '')).lower()\n",
    "            quantite = float(row.get('quantite_totale', 0))\n",
    "            \n",
    "            if unite == 'KG':\n",
    "                return quantite\n",
    "            elif unite == 'L':\n",
    "                return quantite * (self.organic_liquid_density if 'organique' in type_engrais else self.default_mineral_density)\n",
    "            elif unite == 'M3':\n",
    "                return quantite * (self.organic_solid_density if 'organique' in type_engrais else self.default_mineral_density * 1000)\n",
    "            else:\n",
    "                print(f\"Avertissement: Unité non reconnue: {unite} pour l'engrais {row.get('libelle', 'Unknown')}\")\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la conversion pour l'engrais {row.get('libelle', 'Unknown')}: {str(e)}\")\n",
    "            return np.nan\n",
    "\n",
    "    def standardize_mesparcelles(self, data):\n",
    "        print(\"Standardisation des données MesParcelles...\")\n",
    "        \n",
    "        # Filtrer les fertilisations\n",
    "        fertilisation_types = [\n",
    "            \"Fertilisation et amendement organique\",\n",
    "            \"Fertilisation et amendement mineral - foliaire inclus\"\n",
    "        ]\n",
    "        df = data[data['type_intervention.libelle'].isin(fertilisation_types)].copy()\n",
    "        print(f\"Après filtrage : {len(df)} lignes\")\n",
    "        \n",
    "        # Vérifier la présence des colonnes requises\n",
    "        required_columns = [\n",
    "            'libelle', 'unite_intrant_intervention', 'quantite_totale', \n",
    "            'surface_travaillee_ha', 'fertilisant.composition.n_total',\n",
    "            'fertilisant.composition.p', 'fertilisant.composition.k',\n",
    "            'type_intervention.libelle', 'siret_exploitation', 'uuid_parcelle'\n",
    "        ]\n",
    "        \n",
    "        df = df.dropna(subset=required_columns)\n",
    "        \n",
    "        # Standardisation\n",
    "        df['type_engrais'] = df['type_intervention.libelle'].apply(self.standardize_type_engrais)\n",
    "        df['in_icv_list'] = df['libelle'].apply(self.is_in_icv_list)\n",
    "        df['quantite_kg'] = df.apply(self.convert_to_kg, axis=1)\n",
    "        df['dose_kg_ha'] = df['quantite_kg'] / df['surface_travaillee_ha']\n",
    "        \n",
    "        # Calcul des nutriments\n",
    "        df = df.apply(self.calculate_nutrients, axis=1)\n",
    "        \n",
    "        return self._aggregate_by_exploitation(df, 'siret_exploitation')\n",
    "\n",
    "    def standardize_smag(self, data):\n",
    "        print(\"Standardisation des données SMAG...\")\n",
    "        \n",
    "        # Filtrer les fertilisations\n",
    "        fertilisation_types = [\"Fertilisation organique\", \"Fertilisation minérale\"]\n",
    "        df = data[data[\"Type d'intervention\"].isin(fertilisation_types)].copy()\n",
    "        \n",
    "        # Renommage des colonnes\n",
    "        df = df.rename(columns={\n",
    "            'Intrant': 'libelle',\n",
    "            'Unité': 'unite',\n",
    "            'Dose': 'dose',\n",
    "            'Surface intervention sur parcelle': 'surface_travaillee_ha',\n",
    "            'N': 'N_kg_ha',\n",
    "            'P': 'P_kg_ha',\n",
    "            'K': 'K_kg_ha',\n",
    "            'SIRET': 'siret_exploitation',\n",
    "            'Code edi parcelle': 'uuid_parcelle'\n",
    "        })\n",
    "        \n",
    "        # Standardisation\n",
    "        df['type_engrais'] = df[\"Type d'intervention\"].apply(self.standardize_type_engrais)\n",
    "        df['in_icv_list'] = df['libelle'].apply(self.is_in_icv_list)\n",
    "        \n",
    "        # Conversion des doses pour les engrais ICV\n",
    "        df.loc[df['in_icv_list'], 'dose_kg_ha'] = df[df['in_icv_list']].apply(\n",
    "            self.convert_dose_to_kg_ha, axis=1)\n",
    "        \n",
    "        return self._aggregate_by_exploitation(df, 'siret_exploitation')\n",
    "\n",
    "    def convert_dose_to_kg_ha(self, row):\n",
    "        \"\"\"Convertit les doses SMAG en kg/ha\"\"\"\n",
    "        try:\n",
    "            if pd.isna(row.get('unite')) or pd.isna(row.get('dose')):\n",
    "                return np.nan\n",
    "                \n",
    "            unite = str(row['unite']).upper()\n",
    "            if unite == 'KG/HA':\n",
    "                return row['dose']\n",
    "            elif unite == 'L/HA':\n",
    "                return row['dose'] * (\n",
    "                    self.organic_liquid_density \n",
    "                    if row['type_engrais'] == 'engrais organiques' \n",
    "                    else self.default_mineral_density\n",
    "                )\n",
    "            elif unite == 'M3/HA':\n",
    "                return row['dose'] * (\n",
    "                    self.organic_solid_density \n",
    "                    if row['type_engrais'] == 'engrais organiques'\n",
    "                    else self.default_mineral_density * 1000\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Avertissement: Unité non reconnue: {unite} pour l'engrais {row['libelle']}\")\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la conversion pour l'engrais {row['libelle']}: {str(e)}\")\n",
    "            return np.nan\n",
    "\n",
    "    def _aggregate_by_exploitation(self, df, siret_column):\n",
    "        \"\"\"Agrège les données par exploitation avec pondération par surface\"\"\"\n",
    "        print(f\"Agrégation des données par exploitation ({siret_column})...\")\n",
    "        \n",
    "        def weighted_average(group):\n",
    "            # Calcul des moyennes pondérées par surface\n",
    "            result = {}\n",
    "            weights = group['surface_travaillee_ha']\n",
    "            \n",
    "            # Convertir les libellés en strings et supprimer les valeurs NaN\n",
    "            libelles = group['libelle'].apply(lambda x: str(x) if pd.notnull(x) else '').unique()\n",
    "            libelles = [lib for lib in libelles if lib != '']\n",
    "            result['engrais_utilises'] = ', '.join(sorted(libelles, key=str))\n",
    "            \n",
    "            # Pour les engrais ICV\n",
    "            if 'dose_kg_ha' in group.columns:\n",
    "                icv_mask = group['in_icv_list']\n",
    "                if icv_mask.any():\n",
    "                    for fertilizer in group.loc[icv_mask, 'libelle'].unique():\n",
    "                        if pd.notnull(fertilizer):  # Vérifier que le libellé n'est pas NaN\n",
    "                            fertilizer_str = str(fertilizer)\n",
    "                            mask = icv_mask & (group['libelle'].astype(str) == fertilizer_str)\n",
    "                            if mask.any():\n",
    "                                result[f\"{fertilizer_str}_dose_kg_ha\"] = np.average(\n",
    "                                    group.loc[mask, 'dose_kg_ha'],\n",
    "                                    weights=group.loc[mask, 'surface_travaillee_ha']\n",
    "                                )\n",
    "            \n",
    "            # Pour les nutriments (non-ICV)\n",
    "            non_icv_mask = ~group['in_icv_list']\n",
    "            if non_icv_mask.any():\n",
    "                # Ajouter la liste des engrais non-ICV séparément\n",
    "                non_icv_libelles = group.loc[non_icv_mask, 'libelle'].apply(\n",
    "                    lambda x: str(x) if pd.notnull(x) else '').unique()\n",
    "                non_icv_libelles = [lib for lib in non_icv_libelles if lib != '']\n",
    "                result['engrais_non_icv'] = ', '.join(sorted(non_icv_libelles, key=str))\n",
    "                \n",
    "                for nutrient in ['N_kg_ha', 'P_kg_ha', 'K_kg_ha']:\n",
    "                    if nutrient in group.columns:\n",
    "                        values = group.loc[non_icv_mask, nutrient]\n",
    "                        weights_subset = group.loc[non_icv_mask, 'surface_travaillee_ha']\n",
    "                        if not values.empty and not weights_subset.empty:\n",
    "                            result[f\"non_icv_{nutrient}\"] = np.average(\n",
    "                                values,\n",
    "                                weights=weights_subset\n",
    "                            )\n",
    "            \n",
    "            return pd.Series(result)\n",
    "        \n",
    "        # S'assurer que la colonne 'libelle' est de type string\n",
    "        df['libelle'] = df['libelle'].astype(str)\n",
    "        \n",
    "        # Grouper par SIRET et agréger\n",
    "        aggregated = df.groupby(siret_column).apply(weighted_average).reset_index()\n",
    "        print(f\"Données agrégées par exploitation : {len(aggregated)} exploitations\")\n",
    "        return aggregated\n",
    "\n",
    "        # Grouper par SIRET et agréger\n",
    "        aggregated = df.groupby(siret_column).apply(weighted_average).reset_index()\n",
    "        print(f\"Données agrégées par exploitation : {len(aggregated)} exploitations\")\n",
    "        return aggregated\n",
    "\n",
    "    def combine_sources(self, mesparcelles_data, smag_data):\n",
    "        \"\"\"Combine les données des deux sources\"\"\"\n",
    "        print(\"Combinaison des données...\")\n",
    "        \n",
    "        # Standardisation des données\n",
    "        print(\"\\nTraitement des données MesParcelles...\")\n",
    "        mp_std = self.standardize_mesparcelles(mesparcelles_data)\n",
    "        print(\"\\nTraitement des données SMAG...\")\n",
    "        smag_std = self.standardize_smag(smag_data)\n",
    "        \n",
    "        # Ajout de la source\n",
    "        mp_std['source'] = 'mesparcelles'\n",
    "        smag_std['source'] = 'smag'\n",
    "        \n",
    "        # Vérification des colonnes\n",
    "        print(\"\\nColonnes dans les données standardisées:\")\n",
    "        print(\"MesParcelles:\", mp_std.columns.tolist())\n",
    "        print(\"SMAG:\", smag_std.columns.tolist())\n",
    "        \n",
    "        # Combinaison des données\n",
    "        combined = pd.concat([mp_std, smag_std], ignore_index=True)\n",
    "        \n",
    "        # Vérification des résultats\n",
    "        print(\"\\nRésumé des données combinées:\")\n",
    "        print(f\"Nombre total d'observations: {len(combined)}\")\n",
    "        print(f\"Nombre d'exploitations uniques: {combined['siret_exploitation'].nunique()}\")\n",
    "        print(f\"Nombre de cultures uniques: {combined['culture'].nunique()}\")\n",
    "        print(\"\\nListe des cultures uniques:\")\n",
    "        print(combined['culture'].unique())\n",
    "        print(\"\\nNombre d'observations par source et culture:\")\n",
    "        print(combined.groupby(['source', 'culture']).size())\n",
    "        \n",
    "        return combined\n",
    "\n",
    "# Utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chargement des données...\")\n",
    "    \n",
    "    # Import des données\n",
    "    mp_path = r\"C:\\Users\\MonirNajem\\OneDrive - FOOD PILOT\\Desktop\\monir\\MESPARCELLES\\mesparcelles_data.xlsx\"\n",
    "    smag_path = r\"C:\\Users\\MonirNajem\\OneDrive - FOOD PILOT\\Desktop\\monir\\MESPARCELLES\\SMAG.xlsx\"\n",
    "    \n",
    "    mp_data = pd.read_excel(mp_path, sheet_name='Intervention_Details')\n",
    "    smag_data = pd.read_excel(smag_path)\n",
    "    \n",
    "    # Standardisation et combinaison\n",
    "    standardizer = FertilizerStandardizer()\n",
    "    combined_data = standardizer.combine_sources(mp_data, smag_data)\n",
    "    \n",
    "    # Export des résultats\n",
    "    combined_data.to_excel('resultats_standardisation_par_exploitation.xlsx', index=False)\n",
    "    print(\"\\nRésultats exportés dans 'resultats_standardisation_par_exploitation.xlsx'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
